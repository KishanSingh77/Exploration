{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  4.6566e-10,  0.0000e+00],\n",
       "        [ 4.6566e-10,  4.2981e+21,  6.3828e+28]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2541,  0.0715,  0.6239],\n",
       "        [ 0.8283,  0.1828,  0.7581]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  3.,  3.],\n",
       "        [ 3.,  3.,  3.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 3)\n",
    "y = torch.ones(2, 3) * 2\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:, 1] = y[:, 1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  2.],\n",
       "        [ 2.,  4.,  2.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.ones(2, 2) * 2, requires_grad = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 2 * (x * x) + 5 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward(torch.ones(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 13.,  13.],\n",
      "        [ 13.,  13.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 200\n",
    "epochs = 10\n",
    "log_interval = 10\n",
    "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n",
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:13: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.004177\n",
      "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 0.005419\n",
      "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 0.002463\n",
      "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 0.004902\n",
      "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 0.002734\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.007696\n",
      "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.006386\n",
      "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 0.003025\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.005662\n",
      "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 0.003421\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.012084\n",
      "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 0.001939\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.003057\n",
      "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 0.004211\n",
      "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 0.002117\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.003799\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.009131\n",
      "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 0.003730\n",
      "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.004395\n",
      "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 0.007079\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.002980\n",
      "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 0.003103\n",
      "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 0.004783\n",
      "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 0.006957\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.005821\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.005726\n",
      "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 0.009407\n",
      "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 0.006191\n",
      "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.006168\n",
      "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 0.002514\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.001961\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.003708\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.006131\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.002232\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.007280\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.005211\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.004010\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.004352\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.003304\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.002470\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.005671\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.003235\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.002929\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.004468\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.003277\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.011300\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.008959\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.006530\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.003706\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.002853\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.014365\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.005571\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.004436\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.004219\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.001609\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.003827\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.012283\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.006169\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.003274\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.001936\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.002430\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.003481\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.001750\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.005155\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.002901\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.004224\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.002244\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.003204\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.008871\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.002689\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.002073\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.004141\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.004051\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.004477\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.002264\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.004431\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.005993\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.007562\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.005039\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.004685\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.002807\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.005315\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.001201\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.000718\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.004534\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.002517\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.005505\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.003095\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.003440\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.008236\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.003472\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.003818\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.002803\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.004250\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.003111\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.004023\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.003634\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.002415\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.002303\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.001506\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.002806\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.001877\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.002653\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.003431\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.001616\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.001733\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.002384\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.003146\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.003090\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.002590\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.002094\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.003676\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.003459\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.008215\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.002475\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.007585\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.001431\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.002789\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.002880\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.009899\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.002684\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.003098\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.002174\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.002642\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.001832\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.002965\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.001274\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.004785\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.003277\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.003175\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.001468\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.003602\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.003637\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.003996\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.003689\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.004085\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.003420\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.002020\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.002622\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.003536\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.002278\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.005209\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.003581\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.004128\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.003713\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.001461\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.002522\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.004294\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.003025\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.004176\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.002200\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.002447\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.001053\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.001927\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.003991\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.002802\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.002270\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.002304\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.001448\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.002076\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.003428\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.000982\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.002479\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.001298\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.002658\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.001738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.003585\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.003570\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.005261\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.003520\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.002688\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.005120\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.001479\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.003905\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.003913\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.001653\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.004986\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.004558\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.002781\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.003947\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001753\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.001529\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.001149\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.002521\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.003711\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.002662\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.001557\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.002857\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.003028\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.002545\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.002706\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.002762\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.001503\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.003263\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.003533\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.004745\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.001981\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.005666\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.002183\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.002236\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.001135\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.000832\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.002437\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.002215\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.001385\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.002337\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.002743\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.004338\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.005264\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.003019\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.002433\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.001391\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.003471\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.002064\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.004165\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.001553\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.003373\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.002441\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.001996\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.001890\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.002619\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.001324\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.004037\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.004034\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.003196\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.001620\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.001389\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.001743\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.000912\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.001812\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.001454\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.001428\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.002992\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.002450\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.001665\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.003942\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.002659\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.002989\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.001870\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.004133\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.001339\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.001385\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.001753\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.002741\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.001538\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.002375\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.002304\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.002804\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.001944\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.001592\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.003189\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.001361\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.001137\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.003201\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.005758\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.002884\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.001847\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.002907\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.003053\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.001595\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.001290\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.002017\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.001209\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.004807\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.001937\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.003099\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.003561\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.006623\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.002657\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.002201\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.001288\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.002245\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.001899\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.003424\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.002453\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.001232\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.001015\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.001649\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.002440\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.001339\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.001783\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.001782\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.001335\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.003383\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.001669\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.002334\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000591\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.002192\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.001086\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.002477\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.003425\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.002406\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.001694\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.002901\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.001475\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.002041\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.002204\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.002580\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.002107\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.001554\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data = data.view(-1, 28 * 28)\n",
    "        optimizer.zero_grad()\n",
    "        net_out = net(data)\n",
    "        loss = criterion(net_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:3: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n",
      "/Library/Python/2.7/site-packages/ipykernel_launcher.py:6: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-03 *\n",
      "       3.8482)\n",
      "tensor(0.1163)\n",
      "tensor(0.1790)\n",
      "tensor(1.00000e-02 *\n",
      "       7.3233)\n",
      "tensor(1.00000e-02 *\n",
      "       3.7980)\n",
      "tensor(1.00000e-02 *\n",
      "       3.1419)\n",
      "tensor(1.00000e-02 *\n",
      "       8.2084)\n",
      "tensor(0.1410)\n",
      "tensor(0.1105)\n",
      "tensor(1.00000e-02 *\n",
      "       2.8443)\n",
      "tensor(0.1117)\n",
      "tensor(0.1207)\n",
      "tensor(1.00000e-02 *\n",
      "       4.0165)\n",
      "tensor(1.00000e-02 *\n",
      "       5.9876)\n",
      "tensor(0.1137)\n",
      "tensor(0.1045)\n",
      "tensor(1.00000e-02 *\n",
      "       7.3176)\n",
      "tensor(1.00000e-02 *\n",
      "       9.3929)\n",
      "tensor(1.00000e-02 *\n",
      "       2.5744)\n",
      "tensor(0.1563)\n",
      "tensor(1.00000e-02 *\n",
      "       2.6546)\n",
      "tensor(0.1136)\n",
      "tensor(1.00000e-02 *\n",
      "       4.9137)\n",
      "tensor(1.00000e-02 *\n",
      "       6.9535)\n",
      "tensor(1.00000e-02 *\n",
      "       9.3072)\n",
      "tensor(1.00000e-02 *\n",
      "       3.1273)\n",
      "tensor(1.00000e-02 *\n",
      "       6.4904)\n",
      "tensor(1.00000e-02 *\n",
      "       8.7859)\n",
      "tensor(1.00000e-02 *\n",
      "       7.6098)\n",
      "tensor(0.1621)\n",
      "tensor(1.00000e-02 *\n",
      "       3.8164)\n",
      "tensor(1.00000e-02 *\n",
      "       4.8028)\n",
      "tensor(1.00000e-02 *\n",
      "       6.4370)\n",
      "tensor(1.00000e-02 *\n",
      "       4.5228)\n",
      "tensor(1.00000e-02 *\n",
      "       6.9698)\n",
      "tensor(1.00000e-02 *\n",
      "       9.5577)\n",
      "tensor(0.1015)\n",
      "tensor(1.00000e-02 *\n",
      "       6.1614)\n",
      "tensor(0.1115)\n",
      "tensor(0.1384)\n",
      "tensor(0.1446)\n",
      "tensor(0.1064)\n",
      "tensor(1.00000e-02 *\n",
      "       7.6826)\n",
      "tensor(1.00000e-02 *\n",
      "       5.9363)\n",
      "tensor(1.00000e-02 *\n",
      "       4.1027)\n",
      "tensor(1.00000e-02 *\n",
      "       3.8084)\n",
      "tensor(1.00000e-02 *\n",
      "       4.1960)\n",
      "tensor(1.00000e-02 *\n",
      "       2.1820)\n",
      "tensor(1.00000e-02 *\n",
      "       2.0375)\n",
      "tensor(0.1321)\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 9800 / 10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, correct = 0, 0\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile = True), Variable(target)\n",
    "    data = data.view(-1, 28 * 28)\n",
    "    net_out = net(data)\n",
    "    test_loss += criterion(net_out, target).data[0]\n",
    "    print(criterion(net_out, target).data)\n",
    "    pred = net_out.data.max(1)[1]\n",
    "    correct += pred.eq(target.data).sum()\n",
    "    \n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {} / {} ({:.0f}%)\\n\".format(\n",
    "    test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)\n",
    "))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
